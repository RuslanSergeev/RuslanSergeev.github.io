# Задача дообучения параллельно
Пайплайн параллелится. Русский обучается одновременно с другим языком.
Общая идея - распараллеливание обучения как на диаграмме ниже.
Часть сети обучается основным языком, а часть дополнительным.
Дополнительным языком может являться и основной язык и это тоже даёт выигрыш в качестве.
Объясняется это специализацией внешних (верхних) слоёв на акустике, а нижнего - общего
слоя на более высокоуровневых абстракциях.

## Ближайшие дела по задаче
- [x] Проверить обогащение словаря на английском
- [x] Проверить полный пайплайн на английском
- [x] Запустить каскадное обучение рус+англ
- [x] Запустить обучение английского
- [x] Нужен мягкий рестарт обучения.
----
- [x] Исправить диаграмму. Сначала идёт общая сеть.
- [x] Нужно больше тестов
- [x] Игорь добавляет исходники в dev
- [x] В config.json у датасетов появляется новая роль: `train_ext`
- [x] Если есть датасеты с такой ролью, то создаётся ещё один итератор
для этого вида датасетов. Этот итератор передаётся конструктору ASR в `tnn_train`
- [ ] cms-init вектор в json писать с точностью 3 знака и в несколько строк.

***Лингвистический корпус и конфиг для английской модели***:
На машиne dev2
/home/data1/lm_corpus/upper_texts_en
/home/data1/lm_corpus/configs/eng.conf

***Файл для тестирования***:
На машине ruslan@1c
/data1/other_files/600.wav
/data1/other_files/600.txt


## Описание подхода

Общая идея - распараллеливание обучения как на диаграмме ниже.
Часть сети обучается основным языком, а часть дополнительным.
Дополнительным языком может являться и основной язык и это тоже даёт выигрыш в качестве.
Объясняется это специализацией верхнего общего слоя на акустике, которая не зависит от языка.
Нижние слои специализируются на высокоуровневых абстракциях.

## Схема
<!--
[iterator]->data[lstm],
[lstm]->chanel_1[lstm_1],
[lstm]-.-[lstm_2],
[lstm_1]->[log_softmax1],
[lstm_2]-.-[log_softmax2],
[lstm_1]-[note: русская подсеть {bg:wheat}],
[lstm_2]-[note: английская подсеть {bg:wheat}]
-->

![Схема](https://yuml.me/diagram/scruffy/class/[iterator]-%3Edata[lstm],%20[lstm]-%3Echanel_1[lstm_1],%20[lstm]-.-[lstm_2],%20[lstm_1]-%3E[log_softmax1],%20[lstm_2]-.-[log_softmax2],%20[lstm_1]-[note:%20%D1%80%D1%83%D1%81%D1%81%D0%BA%D0%B0%D1%8F%20%D0%BF%D0%BE%D0%B4%D1%81%D0%B5%D1%82%D1%8C%20%7Bbg:wheat%7D],%20[lstm_2]-[note:%20%D0%B0%D0%BD%D0%B3%D0%BB%D0%B8%D0%B9%D1%81%D0%BA%D0%B0%D1%8F%20%D0%BF%D0%BE%D0%B4%D1%81%D0%B5%D1%82%D1%8C%20%7Bbg:wheat%7D])

## Тесты

|layers|neurons|cascade|Wer/Werc|Per/Perc|  
|---|---|---|---|---|  
|2+2|100|True |`52.8923/48.2478`|`30.7993/22.0913`|
|4  |100|False|`73.4679/70.7782`|`50.6357/40.1321`|

В тесте участвовало 25670 файлов

## Конфигурация
В конфигурацию нейронной сети добавить число слоёв для дополнительного языка:
```json
{
"nn_settings": {
        "bidirectional": true,
        "neurons": 256,
        "comment": "число слоёв: либо целое число, например 5. Либо вектор при каскадном обучении, например [2, 3]."
        "layers": [2, 2]
}
}
```
В конфигурацию датасетов добавить датасеты с ролью `train_ext`:
```json
"datasets" : [
      { "audio": "/path/where/audio.tar",
        "dataset_name": "/path/to/save/for/future/using.data",
        "role": "train",
        "parts": 0.2 },
      { "audio": "/mount/films_server/tracks.tar",
        "dataset_name": "/mount/dataserver/tracks.data",
        "role": "train_ext",
        "parts": 0.01 },
      { "audio": "none",
        "dataset_name": "/path/to/ready_dataset.data",
        "role": "test",
        "parts": 0.01 }
    ],
```

## Дополнительно при каскаде:
Размер модели: 491877К
```
[2020-06-27 00:05:55] SpeechBox: INFO: TERRORS	125780
[2020-06-27 00:05:55] SpeechBox: INFO: ALL WORDS	260696
[2020-06-27 00:05:55] SpeechBox: INFO: PH_ERRORS	438760
[2020-06-27 00:05:55] SpeechBox: INFO: PH_TERRORS	314708
[2020-06-27 00:05:55] SpeechBox: INFO: ALL PHONES	1424576
[2020-06-27 00:05:55] SpeechBox: INFO: Memory using: 2751 MB; 2.68652 GB
```

Дополнительно при не-каскаде
```
[2020-06-27 01:32:16] SpeechBox: INFO: ERRORS	239410
[2020-06-27 01:32:16] SpeechBox: INFO: TERRORS	230645
[2020-06-27 01:32:16] SpeechBox: INFO: ALL WORDS	325870
[2020-06-27 01:32:16] SpeechBox: INFO: PH_ERRORS	901680
[2020-06-27 01:32:16] SpeechBox: INFO: PH_TERRORS	714640
[2020-06-27 01:32:16] SpeechBox: INFO: ALL PHONES	1780720
[2020-06-27 01:32:16] SpeechBox: INFO: Memory using: 2728 MB; 2.66406 GB
```

# Каскад рус+английская

Обучение рус+англ 6 эпох, 128 нейронов, 2+2 слоя
Против аналогичного но некаскадного обучения на тех же датасетах.
- Русский датасет: 59.3671 часов
- Английский датасет: 29.1092 часов

|layers|neurons|cascade|Train_loss|Test_loss  
|---|---|---|---|---|  
| 2+2 | 128 | True | -0.2993 | -0.3038 |
|  4  | 128 | False| -0.2049 | -0.2223 |

[Домой](../index.html)
