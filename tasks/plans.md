
# Планы на ближайшее время
- [x] созвониться с Вадимом по поводу csv отчётов.
- [x] разбить выхлоп cicd на критичный и некритичный.
- [x] Разделить стадии обработки и нотификации.
- [x] удалить install_ext скрипт и все его вызовы.
- [ ] Сделать интеграционное тестирование на большем объёме данных.
**Toloka**: 1500 часов
**GPT**: 1500 часов
- [ ] Запросить состав большого интеграционного корпуса у Игоря
- [ ] С каждой релизной моделью должен передаваться результат большого интеграционного теста.
- [ ] Проверить docker с `Python3.7` без `CUDA_RESOLVE_DEVICE_SYMBOLS`
- [ ] тестировать стримовую модель в стримовом режиме.
для этого нужно скрипту test_all указать -stream_bsize 4096
- [ ] изменить название теста pylib_nonstream_model на pylib_file_model
- [ ] на гистограмме сделать beam 5% (шаг по оси x)
- [ ] добавить нотификацию о текущей эпохе и лосе в обучении.
- [ ] добавить ограничение на колличество сообщений об инфинитах в единицу времени.
- [ ] добавить проверку пересечения тренировочного и тестового множества

## задачи по cicd
- [x] добавить CICD в train_sdk_build.sh
- [x] добавить инфу об авторе и коммите
- [x] Заменить старые модели на dev1, dev2, ruslan@1c
- [x] Заменить плохой ussr_test файл на хороший (вер 13), Маякнуть Игорю, чтобы
он сделал тоже самое у себя на машинах.
Либо лечилка, либо универсальный код декодера.
- [x] убрать дубли точек для текущего коммита (фильтровать действительно только последний коммит)
- [x] добавить в функциональное тестирование тесты на релизных моделях. и убрать из интегр. теста.
- [x] добавить выбор логов v6000, v6000_stream (или по всем релизным моделям)
- [x] SUMMARY сделать пожирнее.
- [x] приделать интегр. тест. python api
- [x] Сделать суммарные json-отчёты.
- [x] приделать интегр. тест. на релизных моделях .aibox (ph6000, ph6000_stream)
- [x] сделать чтобы amlm_utts формировался на основе всех существующих транскриптов,
а не только аудио корпусов.
- [x] исключить атрансы из тестового датасета из lm_utts

## задачи по CNN
- [ ] переключить sheduler на test_dataset cnn2d_lstm
- [x] прикрутить weight_decay, а также снизить lr
optimizer = optim.SGD(net.parameters(),
                      lr=0.01,
                      momentum=0.9,
                      weight_decay=1e-6,
                      nesterov=True)
- [x] прислать Игорю статью/видос про нормальные генетические алгоритмы.
- [ ] проверить обучение без заморозки cnn_c_lstm
- [x] написать тестовый скрипт  CICD. train_sdk_build.sh - на основе этого скрипта и его выхлопа.
корпусы: /data/corpus/toloka, .../test, .../train
конфиг: file_example_config.json
- [ ] разобраться с сидом: одинаково ли работают мои эксперименты / эксперимент Игоря
- [v] cnn-кой попробовать сжать время. Чтобы на Lstm шёл вектор сжатый по времени в 2-4 раза.
- [x] включить аугментацию в cnn-ках
- [x] перенести аугментацию в subprocess (или попробовать ray)
- [ ] pitch совместно с pass_freq могут выпасть, если частота слишком большая
- [x] в msg.error параметр flag вызывается не как kwarg, из за этого flag
интерпретируется неправильно.
- [x] Продумать вариант CI/CD: какие скрипты и проверки нам нужны?
- [x] Добавить обработку во всех случаях sp.call.
- [x] по возможности вывести описание ошибки.
выводится номер ошибкиaa

## задачи [19.10]
- [x] переопределить json.dump для массивов. Чтобы массив не выводился в высоту.
- [x] вывод кирилицы в config.json, indent=4
- [x] подобрать параметры sox, для promising-эффекта (жду Игоря)
- [x] попробовать брать только последнее измерение по времени
- [x] прикрутить аугментацию в цнн
- [x] только рекурентки без цнн
- [x] курить фейсбук wav2letter
- [x] убрать данные телеграм бота из конфига перед созданием модели.
- [x] добавить флаг --release в обучение, чтобы папка private удалялась из модели
- [x] добавить возможность писать в несколько чатов: критические и некритические сообщения
- [x] добавить преффикс к сообщениям бота
- [x] составлять каунты по общему текстовому файлу в обучении, ввести blk_pen=1.0
- [x] вынести word_freqs за внутренний цикл
- [x] нормализовать счётчик фонем на миллион. (максимальное значение - миллион, остальные - пропорционально)
- [x] Переложить папку tmp из lm_create в work_dir
- [x] курить downsampling в CNN + Transformer.
- [x] прикручивать CNN

## Новые задачи [05.10]
- [x] курить исходники CNN для MFCC. Попробовать что-то завести.
- [x] собрать сведения о разнице transf в задачах ASR + смотреть исходники (компиляция нескольких статей)
- [x] изучить распознавание речи end to end (без промежуточного преобразование в фонемы, без g2p)
- [x] почитать про конволюционные сети в распознавании речи.
- [x] вставить аугментацию SOX в обучение: tone, tempo, filters.

## Задачи [02.10]
- [x] внедрить `[internal]` и флаг `--internal` в `changelog.py`
- [x] проверить работу cuda с моделью ph6000hv2.aibox, проверить потребление памяти.
- [x] Расписать проблему с `lazy load` для Артёма.
- [x] экспериментировать с потоками. Разбираться с запуском на CPU и GPU
- [x] выкатить тег с `cuda`.
m
## Задачи [11.09]
- [x] cuda device -1 по умолчанию
- [x] заменить assert на throw
- [x] разобраться с параметрами test_all.sh. test_path не виден, но пробрасывается.
- [x] обновить `cuda_11.0`+`cudnn8` на `dev2`
- [v] попробовать расшарить веса для всех нейронных сетей.
- [x] проброс devices в виде map а не vector.
- [x] несколько девайсов в рамках одного процесса.
- [x] сделать быстрое решение с флаго `--fast`, в котором вектора `resize_soft`. (возможно `--cuda_angry`)
- [ ] эксперимент на `dev2` при загруженном `dev1` и разгруженном `dev1`.
- [x] Попробовать передовать только одну копию `cublas_hande`, `cudnn_handle` на всю программу. А не вызывать 10 конструкторов.
документация однозначно говорит, что вызов инициализации библиотеки должен быть однократным.
Продолжение:
- [x] при сборке без `cuda` и с запуском с использованием `cuda` происходит segmentation fault.



## задачи [17.08-21.08]

- [ ] сделать вилку для вызова с GEMM_SLOW.
- [x] проброс параметра -j в build.sh и build_ext.sh
- [x] эксперимент: входы и выходы resize-ятся по мере необходимости.
- [x] эксперимент: входы и выходы разделены
- [x] Убрать дубли весов для всех потоков
- [x] Убрать дубли device_input / device_output.
- [x] Сделать проброс cuda_device в декодер
- [x] Проверить есть ли утечка памяти на sbrf3,
задублировать тест (чтобы гоняло несколько часов)
- [x] Сделать broadcasting в операции A*x+(b <- broadcast a column to array)
- [x] Реинкарнация cuda на сервере dev_1
- [x] проброс параметров cuda в build.sh
- [x] cuda падает на многопоточном тесте.
- [ ] запустить 5-граммную модель на фоне.
- [ ] читать про аккустическую аугментацию корпусов.

## Новые задачи [27.07-31.08]

- [x] Проверить `multithread_pass` `на Android`
- [x] внести изменения в документацию про андроид (какой sdk/ndk/gradle рекомендуется)
- [x] Проверить `multithread_pass` `на uni_LSTM`
- [x] По сабвордам: сделать lm на 4, 5 - граммах.
Поправить arpa_parser.py: fro n in range, for o in range ...
Поправить lm_build.sh, стр. 47
Поправить lm_arpa.h, LM_ORDER
Большая арпа (100_000 сабвордов) с маленьким прунингом для вот такой [конфигурации](../configs/fourgram_bigsub_config.json) не собралась. Нужно перегенерировать арпу и пересобрать модель.
Ветка в репозитории `feature/four_grams_subs_testing`
закоментировать 67 строчку cleanup скрипта lm_build.sh, если потребуется отладка.
- [x] Распараллелить циклы прямого и обратного прохода.
- [x] `g2p` без `_Е` на уровне Python скриптов.
- [ ] Убрать сохранение файла `.priors` (возможно в dnn_proc)
- [x] Реанимировать `cuda`


## Задачи по сабвордам.
- [x] Составить стату по сабвордам в процентах. Сколько процентов односложных,
сколько двусложных и т.д.
- [x] Сделать сабворды `--prune 4 4 5`, удостовериться, что модель адекватная.

## Маленькие задачи
- [x] Проверить каскадное обучение  ru/ru на 100 часовом корпусе, 15 эпох.  
- [x] Сделать `config.json` консольным параметром `run.py`  
- [x] Добавить возможность проброски стадий из консоли параметром.
- [x] Алгоритм поиска лучшей сетки не учитывает смену даты. Latest указывает не туда
и выбирается не та сетка (numpy-файл не тот при обучении в течении нескольких суток)

## Большие задачи
- [ ] Tensorflow lite поднять.
- [ ] Логи в базу данных и сервер.
- [ ] Прикрутить `tensor_board`  
- [ ] поднять `telegram`-сервер для управления/декодирования.
- [ ] Сервер на `flask`, логи и пр. в `SQL-Alchemy`, клиент на модуле `dashboard`  
- [ ] Запустить `lstm` на `tensorflow-lite`  
- [ ] Продолжить `subwords`  
- [ ] Продолжить `g2p` с `attention`  
