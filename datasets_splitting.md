# Решение задачи разбиения датасета

## Постановка задачи:

Предполагается что хранение данных будет осуществляться на сетевом диске в виде
чанков по ~10 часов аудио данных. Например для датасета состоящего из 3000 часов
будет 300 zip архивов.

При обучении новой модели мы хотим удобным способом передавать алгоритму обучения
какие чанки из каких датасетов по каким путям достать для обучения.

Планируется что будет очень много разных комбинаций обучения(120 архивов из
`датасет_1` + 40 архивов  из `датасет_2`,  20+50 архивов и т.д.).

Нам было бы удобно, чтобы можно было заранее для N архивов аудиоданных
(те которые по 10 часов) подготовить N feat файлов. Затем, для обучения модели,
в конфиге будут передаваться пути до  N feat файлов, а не до сырых аудио.

При обучении новой акустической модели, данные должны напрямую подгружаться
из N feat файлов, без дополнительной обработки.


## Предлагаемое решение задачи:

Структура конфигурационного файла будет незначительно изменена на следующую:
```json
{
"paths": {
        "comment" : "<<< {откуда_взять,  куда_сформировать_датасет}",
        "means" : "means/location", #use as means for decoder if specified
},
"datasets" : [
  { "audio": "/mount/am_server1/news.tar",  #check read perms
    "data": "/mount/data_server1/news.data", #check write perms
     "role": "train",  "parts": 0.3 },
  { "audio": "none",  #if none not create
    "data": "/mount/data_server1/movies.data",  
    "role": "train",  "parts": 0.1415 }, #many more
],
"stages": {
        "comment" : "<<< какие стадии необходимо запускать (yes/no) >>>",
        "clean"           :  true,  #вместо clean_and_untar
        "prepare utt"     :  true,  #новая старая стадия
        "make lm"         :  true,  #переименовали стадию make_arpa, utt участвует в обогащении.
        "enhance dict"    :  true,  #обогатить и на основе арпы (она сделает текстовичок)
        "make datasets"   :  true,  #на основе обогащ словаря!
        "train dnet"      :  true,
        "compile model"   :  true,
        "test model"      :  true
    }
}
```

#### Формирование датасетов.  
Если стадия make_datasets не пропускается (значение true напротив соотв. поля в stages),
то будет произведена процедура стандартного формирования dataset-файлов. При этом
предполагается следующая процедура формирования имён:  
в конфигурационном файле указаны источник аудио-данных и путь к датасету.   

#### Использование датасетов
Использование датасетов произойдёт на стадии обучения нейронной сети.
Имена использованных датасетов предоставляются в разделах `train_datasets` и
`test_datasets`.

## Ход работы

#### Использование вектора `means`
Значения `means` вычитаются из вектора фичей в процессоре `cms`. Это происходит
при формировании датасета, а также при обработке аудио-данных (в приложении).

#### Переделана секция `datasets`
```json
{
    "datasets" : [
      {
        "audio": "/mount/am_server1/news.tar", #check read perms
        "data": "/mount/data_server1/news.data", #check write perms
         "role": "train",  
         "parts": 0.3
      }
    ]
}
```
Eсли секция `audio` содержит `none`, то обработка корпуса не будет произведена.
Если не присутствует ни одного необработанного файла, а также отсутствует описание
процесса `cms[means]` необходимо завершить дальнейшую обработку корпуса.

Необходимо формировать один вектор `means` для всех датасетов. Как взвешенная
сумма `means` всех датасетов.

#### Существующие файлы
Теперь на каждой стадии могут использоваться уже Существующие файлы.
```json
{
"stages": {
        "comment" : "<<< какие стадии необходимо запускать (yes/no) >>>",
        "clean"           :  "yes",
        "prepare utt"     :  "yes",
        "make lm"         :  "/data1/models/mega_news.lm.bin",
        "enhance dict"    :  "no",
        "make datasets"   :  "yes",
        "train dnet"      :  "/data1/models/lstm_5l_400n_1300hrs.numpy",
        "compile model"   :  "no",
        "test model"      :  "no"
    }
}
```

#### Формирование атрансов для каждого датасета
Теперь общий файл атрансов формируется только если стадия `prepare_utt`
не пропускается. Для всех датасетов, для которых существуют аудио-корпусы,
будут сформированы атрансы.
Список дирректорий для обхода на стадии разархивации теперь у каждого датасета
индивидуальный.

#### Изменения в `corpus_all`
Упрощен метод формирования индивидуальных датасетов. Теперь метод только
формирует поддиректории с конфигами датасета, если найден соответствующий
audio-архив.

[Домой](index.html)
